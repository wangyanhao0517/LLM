{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAeNyYeLa3qH"
      },
      "source": [
        "# å¤æ—¦LLMå…¥é—¨æ–‡æ¡£ç¬¬äºŒç‰ˆ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# å¯¼è¯»å¤§çº²\n",
        "\n",
        "**è®¤çŸ¥**\n",
        "1. è¯­è¨€æ¨¡å‹ï¼ˆLanguage Modelï¼ŒLMï¼‰çš„ç›®æ ‡å°±æ˜¯å¯¹è‡ªç„¶è¯­è¨€çš„æ¦‚ç‡åˆ†å¸ƒå»ºæ¨¡\n",
        "2. å¤§é¢„è¨€æ¨¡å‹ç¼©æ”¾æ³•åˆ™ï¼Œ å‚æ•°é‡ã€æ•°æ®é‡ã€è®¡ç®—é‡æŒ‡æ•°å¢åŠ çš„è¿‡ç¨‹ï¼Œä¼šä½¿å¾—æ¨¡å‹æ€§èƒ½çº¿æ€§å¢åŠ \n",
        "3. åŸºç¡€æ¨¡å‹æ˜¯æŒ‡ä»…ç»è¿‡é¢„è®­ç»ƒçš„æ¨¡å‹ï¼›å¯¹è¯æ¨¡å‹æ˜¯æŒ‡åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸº\n",
        "ç¡€ä¸Šç»è¿‡æœ‰ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ¨¡å‹ï¼Œå…·å¤‡å¯¹è¯å’Œå®Œæˆä»»åŠ¡çš„èƒ½åŠ›ï¼›æ¨ç†æ¨¡å‹æ˜¯æŒ‡ä¸“æ³¨äº\n",
        "é€»è¾‘æ¨ç†å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹ã€‚\n",
        "4.\n",
        "\n",
        "**ç»Ÿè®¡å­¦**\n",
        "1. æœ€å¤§ä¼¼ç„¶ä¼°è®¡\n",
        "2. N-gramç®—æ³•\n",
        "3. æ•°æ®å¹³æ»‘ã€é›¶æ¦‚ç‡é—®é¢˜\n",
        "\n",
        "\n",
        "**ç¥ç»ç½‘ç»œ**\n",
        "1. 2000å¹´æå‡ºå‰é¦ˆç¥ç»ç½‘ç»œ\n",
        "2. ELMo\n",
        "3. Bertã€ GPT\n",
        "4. 2020å¹´å‘å¸ƒäº†GPT3 ï¼ˆGenerative Pre-trained Transformer 3ï¼‰\n",
        "5. PaLMã€LaMDA\n",
        "\n",
        "\n",
        "**LLM**\n",
        "1. æ ¹æ®OpenAIå…¬å¼€çš„æ–‡æ¡£ï¼Œå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…å«ä»¥ä¸‹å››ä¸ªä¸»è¦è¿‡ç¨‹  \n",
        "  + é¢„è®­ç»ƒ(Pretraining)ï¼šæå‡åˆ†å¸ƒå¼è®­ç»ƒçš„æ•ˆç‡åº”å½“æ˜¯è¯¥é˜¶æ®µæœ€å¤§çš„éš¾ç‚¹\n",
        "  + æœ‰ç›‘ç£å¾®è°ƒ(Supervised Fine Tuningï¼ŒSFT)ï¼šéš¾ç‚¹æ˜¯å¦‚ä½•æ„é€ å°‘é‡å¹¶ä¸”é«˜è´¨é‡çš„ç›‘ç£æ•°æ®\n",
        "  + å¥–åŠ±å»ºæ¨¡(Reward Modeling)ï¼šéš¾ç‚¹æ˜¯é™å®šå¥–åŠ±æ¨¡å‹åº”ç”¨çš„æ³›åŒ–è¾¹ç•Œ\n",
        "  + å¼ºåŒ–å­¦ä¹ (Reinforcement Learningï¼ŒRL)ï¼šè¿™é‡Œç›¸å¯¹è¾ƒå¤æ‚ï¼Œéœ€è¦ä»”ç»†ç ”ç©¶ä¸€ä¸‹ï¼Œå¼ºåŒ–å­¦ä¹ åœ¨æ­¤ç”Ÿæ•ˆçš„æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ  \n",
        "2. å¤§æ¨¡å‹æŠ€æœ¯ç‰ˆå›¾\n",
        "\n",
        "\n",
        "| å±‚çº§ | æ ¸å¿ƒç›®æ ‡ | ä¸»æµæŠ€æœ¯ / æ–¹æ³• | äº¤å‰ & å¯é€‰æŠ€æœ¯ | å¸¸ç”¨æ¡†æ¶ / å·¥å…· |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| **0. æ•°æ® & Tokenizer** | é«˜è´¨è¯­æ–™æ”¶é›†ã€å»å™ªã€åˆ‡è¯ | - Common Crawl / Book / ç¤¾åª’æ¸…æ´—  <br>- é‡é‡‡æ · (CCMix)  <br>- è¯­ä¹‰å»é‡ (MinHash) | - è‡ªåŠ¨æ ‡æ³¨ (self-instruct)  <br>- å¤šè¯­è¯­æ–™å¯¹é½ | Pile Â· OpenWebText Â· tiktoken Â· SentencePiece |\n",
        "| **1. é¢„è®­ç»ƒ (Foundation)** | å­¦é€šç”¨è¯­è¨€ / å¤šæ¨¡æ€è¡¨å¾ | - è‡ªå›å½’ / Mask LLM  <br>- MoE æ‰©å®¹ (GShard / Switch-MoE)  <br>- å¤šæ¨¡æ€å¯¹é½ (ALIGN, BLIP-2) | - ä½ç²¾åº¦ä¼˜åŒ– (8-bit Adam, FP8)  <br>- èŠ‚ç‚¹å¹¶è¡Œ (TP / PP) | Megatron-LM Â· DeepSpeed-Megatron Â· PaLM-RLHF Â· Fuyu |\n",
        "| **2. å¯¹é½è®­ç»ƒ (Alignment)** | è®©æ¨¡å‹â€œå¬è¯ + è®¨å–œâ€ | - **SFT** (å…¨å‚ / LoRA / QLoRA)  <br>- **RM** (Pairwise Ranking)  <br>- **RLHF** (PPO-KL) | - **DPO / IPO**  <br>- **RLAIF** (AI-feedback)  <br>- å®¡æ ¡å¾®è°ƒ (Refusal / Detox) | HF Trainer Â· trlX Â· DeepSpeed-Chat |\n",
        "| **3. å‹ç¼© & éƒ¨ç½²å‡†å¤‡** | é™æ˜¾å­˜ã€æåå | - é‡åŒ– (8 / 4 / 2-bit, GPTQ, AWQ)  <br>- è’¸é¦ (TinyLlama, DistilGPT-2)  <br>- FlashAttention-2 / xformers | - åŠ¨æ€ KV Cache (PagedAttention)  <br>- Parameter-Efficient MoE æ‹†åˆ† | bitsandbytes Â· auto-gptq Â· FT-Transformer |\n",
        "| **4. æ¨ç† & ç¼–æ’ (Inference / Orchestration)** | å®æ—¶é—®ç­”ã€å·¥å…·è°ƒç”¨ã€å®Œæˆå¤æ‚ä»»åŠ¡ | - **RAG** (å‘é‡æ£€ç´¢ + Prompt æ‹¼æ¥)  <br>- **Agent / Tool Calling** (ReAct, Auto-GPT)  <br>- æ‰¹è°ƒåº¦ / vLLM  <br>- Guardrails / Policy-RM å¤å®¡ | - é•¿ä¸Šä¸‹æ–‡ (Rope-Scaling, Flash-Infer)  <br>- Memory / Retriever-Augmented Agent | vLLM Â· TGI Â· LangChain Â· Llama-Index Â· OpenAI Functions |\n"
      ],
      "metadata": {
        "id": "LXMm62VzcPoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# åŸºç¡€çŸ¥è¯†"
      ],
      "metadata": {
        "id": "dvY16dh1bhOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers\n",
        "1. ä½ç½®ç¼–ç \n",
        "ç¬¬ä¸€ï¼Œæ­£ä½™å¼¦å‡½æ•°çš„èŒƒå›´æ˜¯ [âˆ’1, +1]ï¼Œå¯¼å‡ºçš„ä½ç½®ç¼–ç ä¸åŸè¯åµŒå…¥ç›¸åŠ ä¸ä¼šä½¿å¾—ç»“æœåç¦»è¿‡è¿œè€Œç ´ååŸæœ‰å•è¯çš„è¯­ä¹‰ä¿¡æ¯ï¼›ç¬¬äºŒï¼Œä¾æ®ä¸‰è§’å‡½æ•°çš„åŸºæœ¬æ€§è´¨ï¼Œå¯ä»¥å¾—çŸ¥ç¬¬ pos + k ä¸ªä½ç½®ç¼–ç æ˜¯ç¬¬ pos ä¸ªä½ç½®ç¼–ç çš„çº¿æ€§ç»„åˆï¼Œè¿™å°±æ„å‘³ç€ä½ç½®ç¼–ç ä¸­è•´å«ç€å•è¯ä¹‹é—´çš„è·ç¦»ä¿¡æ¯ã€‚  \n",
        "2."
      ],
      "metadata": {
        "id": "9fHwFtv3QHSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "id": "vgPZDEyQTRMi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wFn1EifkbBkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c97f02-ad3b-4ba5-ac2a-c3d9ae656218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 24])\n",
            "tensor([[ 0.9093, -0.4161,  0.9021,  0.4315,  0.5911,  0.8066,  0.3482,  0.9374,\n",
            "          0.1987,  0.9801,  0.1122,  0.9937,  0.0632,  0.9980,  0.0356,  0.9994,\n",
            "          0.0200,  0.9998,  0.0112,  0.9999,  0.0063,  1.0000,  0.0036,  1.0000]])\n"
          ]
        }
      ],
      "source": [
        "# ä¸‰è§’å‡½æ•°ä½ç½®ç¼–ç \n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_seq_len, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "        pe = torch.zeros(self.max_seq_len, self.d_model)\n",
        "        for pos in range(self.max_seq_len):\n",
        "            for i in range(0, self.d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / pow(1000, i / self.d_model))\n",
        "                pe[pos, i + 1] = math.cos(pos / pow(1000, i / self.d_model))\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe) # éšå‚æ•°ä¿å­˜ï¼ŒåŒæ—¶ä¸å‚ä¸æ¢¯åº¦è®¡ç®—\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "\n",
        "        # å åŠ ä½ç½®ç¼–ç \n",
        "        x = x + self.pe[:, x.size(1), :] # å¦‚æœéœ€è¦ä½¿ç”¨æ˜¾å¡ï¼Œè¿™é‡Œéœ€è¦to device\n",
        "        return x\n",
        "pe = PositionalEncoding(8, 24)\n",
        "print(pe.pe.shape)\n",
        "print(pe.pe[:, 2, :])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶"
      ],
      "metadata": {
        "id": "_NbYff0gcPUU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å‰é¦ˆç¥ç»ç½‘ç»œ"
      ],
      "metadata": {
        "id": "s1CfYiiHamKS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æ®‹å·®ç½‘ç»œ\n",
        "# å…¶å®è¿™é‡Œéœ€è¦è§£é‡Šä¸€ä¸‹ï¼Œä¸ºä»€ä¹ˆæ®‹å·®é“¾æ¥å‘¢èƒ½è§£å†³æç£æ¶ˆå¤±çš„é—®é¢˜ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "GuQUj608eXJi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å±‚æ­£åˆ™åŒ–\n",
        "# å‡å¦‚ç»´åº¦æ˜¯(batch_size, seq_len, hidden_dim)ï¼Œæ¯ä¸ªæ ·æœ¬ã€æ¯ä¸ªtokenéƒ½è¿›è¡Œå•ç‹¬çš„å¤„ç†ï¼Œä½†æ˜¯embeddingç»´åº¦æ˜¯è¿›è¡Œå‡å€¼ã€æ–¹å·®å½’ä¸€åŒ–æ“ä½œ\n",
        "x = torch.tensor([\n",
        "    [ [1.0, 2.0, 3.0, 4.0],\n",
        "      [5.0, 6.0, 7.0, 8.0] ],\n",
        "\n",
        "    [ [2.0, 4.0, 6.0, 8.0],\n",
        "      [1.0, 1.0, 1.0, 1.0] ]\n",
        "])\n",
        "\n",
        "layer_norm = nn.LayerNorm(normalized_shape=4)\n",
        "out = layer_norm(x)\n",
        "print(out)\n",
        "# ä½œç”¨ï¼šLayerNorm çš„ä½œç”¨æ˜¯ï¼šå¯¹æ¯ä¸ª token çš„å‘é‡åšæ ‡å‡†åŒ–ï¼Œä½¿å…¶ç‰¹å¾å€¼æ›´å‡è¡¡ã€è®­ç»ƒæ›´ç¨³å®šã€æ›´é€‚åˆåºåˆ—ä»»åŠ¡ã€‚\n",
        "# è¿™é‡Œéœ€è¦å¯¹æ¯”batch norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTW4qy3webW3",
        "outputId": "d99a9b31-ea9b-40ef-e826-e00c105420bf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
            "         [-1.3416, -0.4472,  0.4472,  1.3416]],\n",
            "\n",
            "        [[-1.3416, -0.4472,  0.4472,  1.3416],\n",
            "         [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer å±‚ä¹‹é—´å †å çš„æ–¹å¼ä¹Ÿè¦äº†è§£æ¸…æ¥šï¼Œå‘é‡æ˜¯æ€ä¹ˆè¿›è¡Œä¼ é€’çš„ï¼Ÿ"
      ],
      "metadata": {
        "id": "UTCI445_gkq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdJZILSikxJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç”Ÿæˆå¼é¢„è®­ç»ƒé¢„è¨€æ¨¡å‹\n",
        "\n",
        "\n",
        "### æŸå¤±å‡½æ•°ï¼šGPT è®­ç»ƒç›®æ ‡ï¼šæœ€å¤§ä¼¼ç„¶ä¼°è®¡ vs äº¤å‰ç†µæŸå¤±ï¼ˆå®Œæ•´æ¨å¯¼ï¼‰\n",
        "\n",
        "åœ¨ GPT æ¨¡å‹ä¸­ï¼Œè®­ç»ƒçš„æ ¸å¿ƒç›®æ ‡æ˜¯ï¼šç»™å®šä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼Œæœ€å¤§åŒ–è¯¥åºåˆ—å‡ºç°çš„æ¦‚ç‡ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªé•¿åº¦ä¸º $n$ çš„ token åºåˆ—ï¼š\n",
        "\n",
        "$$\n",
        "w = (w_1, w_2, \\dots, w_n)\n",
        "$$\n",
        "\n",
        "#### ğŸ¯ ä¸€ã€æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimation, MLEï¼‰\n",
        "\n",
        "æˆ‘ä»¬å¸Œæœ›å­¦ä¹ æ¨¡å‹å‚æ•° $\\theta$ï¼Œä½¿å¾—è¯¥åºåˆ—åœ¨æ¨¡å‹ä¸‹çš„æ¡ä»¶æ¦‚ç‡æœ€å¤§ï¼š\n",
        "\n",
        "$$\n",
        "P(w; \\theta) = \\prod_{i=1}^{n} P(w_i \\mid w_{<i}; \\theta)\n",
        "$$\n",
        "\n",
        "å–å¯¹æ•°åï¼Œå¾—åˆ°å¯¹æ•°ä¼¼ç„¶ï¼ˆlog-likelihoodï¼‰ï¼š\n",
        "\n",
        "$$\n",
        "\\log P(w; \\theta) = \\sum_{i=1}^{n} \\log P(w_i \\mid w_{<i}; \\theta)\n",
        "$$\n",
        "\n",
        "**è®­ç»ƒç›®æ ‡ï¼šæœ€å¤§åŒ– log-likelihoodï¼Œå³æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰ï¼š**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{MLE}}(\\theta) = \\max_{\\theta} \\sum_{i=1}^{n} \\log P(w_i \\mid w_{<i}; \\theta)\n",
        "$$\n",
        "\n",
        "ä¸ºäº†è¿›è¡Œä¼˜åŒ–ï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºæœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNegative Log-Likelihood, NLLï¼‰ï¼š\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{NLL}}(\\theta) = - \\sum_{i=1}^{n} \\log P(w_i \\mid w_{<i}; \\theta)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### ğŸ” äºŒã€äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropy Lossï¼‰\n",
        "\n",
        "åœ¨å®ç°ä¸­ï¼Œä»¤ $P_{\\text{true}}^{(i)}(v)$ è¡¨ç¤ºç¬¬ $i$ ä¸ª token çš„çœŸå®åˆ†å¸ƒï¼ˆé€šå¸¸æ˜¯ one-hot å‘é‡ï¼‰ï¼Œ\n",
        "$P_{\\text{pred}}^{(i)}(v)$ è¡¨ç¤ºæ¨¡å‹åœ¨ä½ç½® $i$ ä¸Šçš„ softmax æ¦‚ç‡è¾“å‡ºã€‚\n",
        "\n",
        "å¯¹äºç¬¬ $i$ ä¸ª tokenï¼Œäº¤å‰ç†µä¸ºï¼š\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{CE}}^{(i)} = - \\sum_{v \\in \\mathcal{V}} P_{\\text{true}}^{(i)}(v) \\log P_{\\text{pred}}^{(i)}(v)\n",
        "$$\n",
        "\n",
        "è‹¥çœŸå®æ ‡ç­¾æ˜¯ one-hotï¼Œå³ $P_{\\text{true}}^{(i)}(v) = 1$ å½“ä¸”ä»…å½“ $v = w_i$ï¼Œåˆ™è¯¥å¼ç®€åŒ–ä¸ºï¼š\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{CE}}^{(i)} = - \\log P_{\\text{pred}}^{(i)}(w_i)\n",
        "$$\n",
        "\n",
        "æœ€ç»ˆæ•´æ¡åºåˆ—çš„äº¤å‰ç†µæŸå¤±ä¸ºï¼š\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{CE}} = \\sum_{i=1}^n \\mathcal{L}_{\\text{CE}}^{(i)} = - \\sum_{i=1}^n \\log P_{\\text{pred}}^{(i)}(w_i)\n",
        "$$\n",
        "\n",
        "è¿™æ­£æ˜¯è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼ˆNLLï¼‰çš„å®šä¹‰ï¼Œå› æ­¤ï¼š\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{CE}} = \\mathcal{L}_{\\text{NLL}}\n",
        "$$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### âœ… ä¸‰ã€ç»“è®ºï¼šMLE ä¸äº¤å‰ç†µæœ¬è´¨ç­‰ä»·\n",
        "\n",
        "| ç†è®ºåç§°                   | æ•°å­¦è¡¨è¾¾                      | å®ç°åç§°                       | æ˜¯å¦ç­‰ä»· |\n",
        "|----------------------------|-------------------------------|-------------------------------|----------|\n",
        "| æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰        | max log P(w_i \\| w_{<i})      | -                             | âœ…       |\n",
        "| è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNLLï¼‰          | - log P(w_i \\| w_{<i})        | -                             | âœ…       |\n",
        "| äº¤å‰ç†µæŸå¤±ï¼ˆCrossEntropyï¼‰ | - log P_pred(w_i)             | PyTorchä¸­çš„ CrossEntropyLoss | âœ…       |\n",
        "\n",
        "\n",
        "\n",
        "å› æ­¤ï¼Œåœ¨ GPT æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸è¯´ï¼š\n",
        "\n",
        "> æ¨¡å‹è®­ç»ƒç›®æ ‡æ˜¯æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶ï¼Œä½†å®ç°ä¸­æˆ‘ä»¬ä½¿ç”¨ç­‰ä»·çš„äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥æœ€å°åŒ–ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### è®­ç»ƒ\n",
        "åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œä¸‹æ¸¸ä»»åŠ¡é’ˆå¯¹ä»»åŠ¡ç›®æ ‡è¿›è¡Œä¼˜åŒ–ï¼Œå¾ˆå®¹æ˜“ä½¿å¾—æ¨¡å‹é—å¿˜é¢„è®­ç»ƒé˜¶æ®µæ‰€å­¦ä¹ çš„é€š\n",
        "ç”¨è¯­ä¹‰çŸ¥è¯†è¡¨ç¤ºï¼Œä»è€ŒæŸå¤±æ¨¡å‹çš„é€šç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå¯¼è‡´å‡ºç°ç¾éš¾æ€§é—å¿˜ï¼ˆCatastrophic Forgettingï¼‰é—®é¢˜ã€‚å› æ­¤ï¼Œé€šå¸¸é‡‡ç”¨æ··åˆé¢„è®­ç»ƒä»»åŠ¡æŸå¤±å’Œä¸‹æ¸¸å¾®è°ƒæŸå¤±çš„æ–¹æ³•æ¥ç¼“è§£ä¸Šè¿°é—®é¢˜"
      ],
      "metadata": {
        "id": "IUb9IgS3kxom"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsXqD-qPk46k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}