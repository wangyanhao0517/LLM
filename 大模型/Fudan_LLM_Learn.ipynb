{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAeNyYeLa3qH"
      },
      "source": [
        "# 复旦LLM入门文档第二版"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 导读大纲\n",
        "\n",
        "**认知**\n",
        "1. 语言模型（Language Model，LM）的目标就是对自然语言的概率分布建模\n",
        "2. 大预言模型缩放法则， 参数量、数据量、计算量指数增加的过程，会使得模型性能线性增加\n",
        "3. 基础模型是指仅经过预训练的模型；对话模型是指在预训练模型基\n",
        "础上经过有监督微调和强化学习训练的模型，具备对话和完成任务的能力；推理模型是指专注于\n",
        "逻辑推理增强的大语言模型。\n",
        "4.\n",
        "\n",
        "**统计学**\n",
        "1. 最大似然估计\n",
        "2. N-gram算法\n",
        "3. 数据平滑、零概率问题\n",
        "\n",
        "\n",
        "**神经网络**\n",
        "1. 2000年提出前馈神经网络\n",
        "2. ELMo\n",
        "3. Bert、 GPT\n",
        "4. 2020年发布了GPT3 （Generative Pre-trained Transformer 3）\n",
        "5. PaLM、LaMDA\n",
        "\n",
        "\n",
        "**LLM**\n",
        "1. 根据OpenAI公开的文档，大语言模型训练过程，包含以下四个主要过程  \n",
        "  + 预训练(Pretraining)：提升分布式训练的效率应当是该阶段最大的难点\n",
        "  + 有监督微调(Supervised Fine Tuning，SFT)：难点是如何构造少量并且高质量的监督数据\n",
        "  + 奖励建模(Reward Modeling)：难点是限定奖励模型应用的泛化边界\n",
        "  + 强化学习(Reinforcement Learning，RL)：这里相对较复杂，需要仔细研究一下，强化学习在此生效的机制是什么？  \n",
        "2. 大模型技术版图\n",
        "\n",
        "\n",
        "| 层级 | 核心目标 | 主流技术 / 方法 | 交叉 & 可选技术 | 常用框架 / 工具 |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| **0. 数据 & Tokenizer** | 高质语料收集、去噪、切词 | - Common Crawl / Book / 社媒清洗  <br>- 重采样 (CCMix)  <br>- 语义去重 (MinHash) | - 自动标注 (self-instruct)  <br>- 多语语料对齐 | Pile · OpenWebText · tiktoken · SentencePiece |\n",
        "| **1. 预训练 (Foundation)** | 学通用语言 / 多模态表征 | - 自回归 / Mask LLM  <br>- MoE 扩容 (GShard / Switch-MoE)  <br>- 多模态对齐 (ALIGN, BLIP-2) | - 低精度优化 (8-bit Adam, FP8)  <br>- 节点并行 (TP / PP) | Megatron-LM · DeepSpeed-Megatron · PaLM-RLHF · Fuyu |\n",
        "| **2. 对齐训练 (Alignment)** | 让模型“听话 + 讨喜” | - **SFT** (全参 / LoRA / QLoRA)  <br>- **RM** (Pairwise Ranking)  <br>- **RLHF** (PPO-KL) | - **DPO / IPO**  <br>- **RLAIF** (AI-feedback)  <br>- 审校微调 (Refusal / Detox) | HF Trainer · trlX · DeepSpeed-Chat |\n",
        "| **3. 压缩 & 部署准备** | 降显存、提吞吐 | - 量化 (8 / 4 / 2-bit, GPTQ, AWQ)  <br>- 蒸馏 (TinyLlama, DistilGPT-2)  <br>- FlashAttention-2 / xformers | - 动态 KV Cache (PagedAttention)  <br>- Parameter-Efficient MoE 拆分 | bitsandbytes · auto-gptq · FT-Transformer |\n",
        "| **4. 推理 & 编排 (Inference / Orchestration)** | 实时问答、工具调用、完成复杂任务 | - **RAG** (向量检索 + Prompt 拼接)  <br>- **Agent / Tool Calling** (ReAct, Auto-GPT)  <br>- 批调度 / vLLM  <br>- Guardrails / Policy-RM 复审 | - 长上下文 (Rope-Scaling, Flash-Infer)  <br>- Memory / Retriever-Augmented Agent | vLLM · TGI · LangChain · Llama-Index · OpenAI Functions |\n"
      ],
      "metadata": {
        "id": "LXMm62VzcPoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 基础知识"
      ],
      "metadata": {
        "id": "dvY16dh1bhOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers\n",
        "1. 位置编码\n",
        "第一，正余弦函数的范围是 [−1, +1]，导出的位置编码与原词嵌入相加不会使得结果偏离过远而破坏原有单词的语义信息；第二，依据三角函数的基本性质，可以得知第 pos + k 个位置编码是第 pos 个位置编码的线性组合，这就意味着位置编码中蕴含着单词之间的距离信息。  \n",
        "2."
      ],
      "metadata": {
        "id": "9fHwFtv3QHSp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFn1EifkbBkY"
      },
      "outputs": [],
      "source": [
        "# 三角函数位置编码\n",
        "class PositionalEncoding():\n",
        "    def __init__(self) -> None:\n",
        "        return\n",
        "\n",
        "    def forward():\n",
        "      return\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NbYff0gcPUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}